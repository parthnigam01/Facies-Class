{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import pandas as pd\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "#from xgboost import XGBClassifier\n",
    "#from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,cross_val_score\n",
    "import numpy as np\n",
    "import pickle \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics  import roc_auc_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "data=pd.read_csv('training_data.csv')\n",
    "\n",
    "data.drop(columns=['Formation','Well Name'], inplace=True) # Dropping categorical data\n",
    "\n",
    "# Dividing Feature and Target columns\n",
    "x=data.drop(columns=['Facies'])\n",
    "y=data['Facies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 8, 6, 7, 4, 5, 9, 1], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #spliting data into training set and holding 50 % of data\n",
    "    train,val_train,test,val_test=train_test_split(x,y,test_size=0.5)\n",
    "    \n",
    "    # spliting training data into training and test data\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1616, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3232, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model objects\n",
    "#xgb=XGBClassifier()\n",
    "rfr=RandomForestClassifier()\n",
    "svm=SVC()\n",
    "lgbm=LGBMClassifier()\n",
    "#xgb=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= GridSearchCV(LGBMClassifier(objective='multiclass') param_grid, verbose=3,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       198\n",
      "           2       1.00      1.00      1.00       588\n",
      "           3       1.00      1.00      1.00       499\n",
      "           4       1.00      1.00      1.00       147\n",
      "           5       1.00      1.00      1.00       176\n",
      "           6       1.00      1.00      1.00       364\n",
      "           7       1.00      1.00      1.00        77\n",
      "           8       1.00      1.00      1.00       403\n",
      "           9       1.00      1.00      1.00       133\n",
      "\n",
      "    accuracy                           1.00      2585\n",
      "   macro avg       1.00      1.00      1.00      2585\n",
      "weighted avg       1.00      1.00      1.00      2585\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.97      0.94        61\n",
      "           2       0.86      0.84      0.85       150\n",
      "           3       0.79      0.83      0.81       116\n",
      "           4       0.78      0.68      0.72        37\n",
      "           5       0.72      0.63      0.68        41\n",
      "           6       0.74      0.77      0.75        98\n",
      "           7       0.78      0.86      0.82        21\n",
      "           8       0.72      0.75      0.74        95\n",
      "           9       0.96      0.86      0.91        28\n",
      "\n",
      "    accuracy                           0.80       647\n",
      "   macro avg       0.81      0.80      0.80       647\n",
      "weighted avg       0.80      0.80      0.80       647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "model=lgbm.fit( x_train, y_train)\n",
    "pred_=model.predict(x_test)\n",
    "#pred_=np.column_stack(pred_)\n",
    "#confusion_matrix(y_test,pred_)\n",
    "#print(classification_report(y_train,model.predict(x_train)))\n",
    "print(classification_report(y_test,pred_))\n",
    "#model.score(y_test,pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1536 candidates, totalling 7680 fits\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.685, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.669, total=   0.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.710, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.681, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.669, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.685, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.669, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.710, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.681, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.669, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.658, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.692, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.683, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.671, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.658, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.692, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.683, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.671, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.654, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.669, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.644, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.654, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.669, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.644, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.689, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.656, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.712, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.673, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.656, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.689, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.656, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.712, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.673, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.656, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.692, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.654, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.704, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.665, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.648, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.692, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.654, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.704, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.665, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.648, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.658, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.677, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.650, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.658, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.677, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=6, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.650, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.720, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.663, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.714, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.694, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.720, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.663, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.714, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.694, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.663, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.687, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.665, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.663, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.687, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.665, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.727, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.710, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.727, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.710, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.710, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.662, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.702, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.689, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.710, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.662, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.702, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.689, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.694, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.694, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.675, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.696, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.671, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.677, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.683, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.671, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.677, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=8, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.683, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.723, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.691, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.727, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.704, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.723, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.691, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.727, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.704, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.723, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.692, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.716, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.723, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.692, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.716, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.733, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.679, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.716, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.702, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.708, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.733, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.679, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.716, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.702, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.708, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.687, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.687, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.700, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.737, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.673, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.714, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.737, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.673, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.714, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.720, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.681, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.723, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.720, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.681, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.721, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=12, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.723, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.735, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.698, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.741, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.725, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.735, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.698, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.741, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.725, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.689, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.731, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.729, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.721, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.689, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.731, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.718, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.2, subsample=0.75, score=0.729, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.729, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.694, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.735, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.716, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.7, score=0.729, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.729, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.694, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.735, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.716, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1, reg_lambda=1.4, subsample=0.75, score=0.729, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.687, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.739, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.714, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.7, score=0.737, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.687, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.739, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.714, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1, subsample=0.75, score=0.737, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.737, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.691, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.741, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7, score=0.720, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.737, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.691, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.741, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.2, subsample=0.75, score=0.720, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.733, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.691, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.749, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.7, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.733, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.691, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.749, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.706, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=10, num_leaves=16, reg_alpha=1.2, reg_lambda=1.4, subsample=0.75, score=0.721, total=   0.1s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.731, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.702, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.766, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.735, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.7, score=0.743, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.731, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.702, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.766, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.735, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1, subsample=0.75, score=0.743, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.733, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.691, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n",
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.758, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7, score=0.718, total=   0.2s\n",
      "[CV] colsample_bytree=0.65, learning_rate=0.5, n_estimators=50, num_leaves=6, reg_alpha=1, reg_lambda=1.2, subsample=0.7 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2ac6b05395c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;31m# finding the best parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Parameter is :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# extracting the best parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    845\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    848\u001b[0m                                         \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m                                         \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[0;32m    613\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2458\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2460\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "\n",
    "                'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "                'n_estimators': [10, 50, 100, 200],\n",
    "                'num_leaves': [6,8,12,16],\n",
    "                'colsample_bytree' : [0.65, 0.66],\n",
    "                'subsample' : [0.7,0.75],\n",
    "                'reg_alpha' : [1,1.2],\n",
    "                'reg_lambda' : [1,1.2,1.4],\n",
    "\n",
    "            }\n",
    "            # Creating an object of the Grid Search class\n",
    "grid= GridSearchCV(LGBMClassifier(objective='multiclass'),param_grid, verbose=3,cv=5)\n",
    "            # finding the best parameters\n",
    "grid.fit(x_train,y_train)\n",
    "print(\"Best Parameter is :\",grid.best_params_,grid.best_score_)\n",
    "            # extracting the best parameters\n",
    "learning_rate = grid.best_params_['learning_rate']\n",
    "n_estimators = grid.best_params_['n_estimators']\n",
    "num_leaves = grid.best_params_['num_leaves']\n",
    "colsample_bytree =grid.best_params_['colsample_bytree']\n",
    "subsample = grid.best_params_['subsample']\n",
    "reg_alpha = grid.best_params_['reg_alpha']\n",
    "reg_lambda = grid.best_params_['reg_lambda']\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "            # creating a new model with the best parameters\n",
    "#lgbm = LGBMClassifier(learning_rate=learning_rate, n_estimators=n_estimators,num_leaves=num_leaves,\n",
    "                      #colsample_bytree=colsample_bytree,subsample=subsample,reg_alpha=reg_alpha,reg_lambda=reg_lambda)\n",
    "            # training the mew model\n",
    "lgbm.fit( x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'multiclass',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "# To view the default model params:\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams,\n",
    "                    verbose=0,\n",
    "                    cv=4,\n",
    "                    n_jobs=2)\n",
    "# Run the grid\n",
    "grid.fit(allTrainData, allTrainLabels)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_for_random_forest(x_train,y_train,rfr):\n",
    "        \"\"\"\n",
    "                                Method Name: get_best_params_for_random_forest\n",
    "                                Description: get the parameters for Random Forest Algorithm which give the best accuracy.\n",
    "                                             Use Hyper Parameter Tuning.\n",
    "                                Output: The model with the best parameters\n",
    "                                On Failure: Raise Exception\n",
    "\n",
    "                                Written By: iNeuron Intelligence\n",
    "                                Version: 1.0\n",
    "                                Revisions: None\n",
    "\n",
    "                        \"\"\"\n",
    "        try:\n",
    "            # initializing with different combination of parameters\n",
    "            param_grid = {\"n_estimators\": [10, 50, 100, 130], \"criterion\": ['gini', 'entropy'],\n",
    "                               \"max_depth\": range(2, 4, 1), \"max_features\": ['auto', 'log2']}\n",
    "\n",
    "            #Creating an object of the Grid Search class\n",
    "            grid = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=5,  verbose=3)\n",
    "            #finding the best parameters\n",
    "            grid.fit(x_train,y_train)\n",
    "\n",
    "            #extracting the best parameters\n",
    "            criterion = grid.best_params_['criterion']\n",
    "            max_depth = grid.best_params_['max_depth']\n",
    "            max_features = grid.best_params_['max_features']\n",
    "            n_estimators = grid.best_params_['n_estimators']\n",
    "\n",
    "            #creating a new model with the best parameters\n",
    "            rfr = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion,\n",
    "                                              max_depth=max_depth, max_features=max_features)\n",
    "            # training the mew model\n",
    "            rfr.fit(x_train,y_train)\n",
    "            \n",
    "            return rfr\n",
    "        except Exception as e:\n",
    "            \n",
    "            raise Exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=10, score=0.451, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=10, score=0.493, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=10 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=10, score=0.456, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=10, score=0.468, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=10, score=0.489, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=50, score=0.447, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=50, score=0.462, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=50, score=0.484, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=50, score=0.453, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=50, score=0.538, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=100, score=0.513, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=100, score=0.470, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=100, score=0.466, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=100, score=0.447, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=100, score=0.455, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=130, score=0.499, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=130, score=0.485, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=130, score=0.462, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=130, score=0.456, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=auto, n_estimators=130, score=0.491, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=10, score=0.491, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=10, score=0.489, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=10, score=0.468, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=10, score=0.433, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=10, score=0.526, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=50, score=0.501, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=50, score=0.482, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=50, score=0.462, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=50, score=0.458, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=50, score=0.528, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=100, score=0.509, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=100, score=0.485, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=100, score=0.485, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=100, score=0.493, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=100, score=0.522, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=130, score=0.485, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=130, score=0.489, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=130, score=0.474, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=130, score=0.495, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=2, max_features=log2, n_estimators=130, score=0.528, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=10, score=0.538, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=10, score=0.509, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=10, score=0.493, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=10, score=0.547, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=10, score=0.561, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=50, score=0.549, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=50, score=0.549, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=50, score=0.522, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=50, score=0.524, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=50, score=0.561, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=100, score=0.549, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=100 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=100, score=0.513, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=100, score=0.522, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=100, score=0.551, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=100, score=0.571, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=130, score=0.551, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=130, score=0.538, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=130, score=0.534, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=130, score=0.547, total=   0.6s\n",
      "[CV] criterion=gini, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=auto, n_estimators=130, score=0.551, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=10, score=0.534, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=10, score=0.524, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=10, score=0.540, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=10, score=0.544, total=   0.0s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=10 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=10, score=0.551, total=   0.1s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=50, score=0.559, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=50, score=0.538, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=50, score=0.545, total=   0.2s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=50, score=0.540, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=50 .\n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=50, score=0.547, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=100, score=0.569, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=100, score=0.522, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=100, score=0.536, total=   0.6s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=100, score=0.565, total=   0.5s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=100, score=0.563, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=130, score=0.563, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=130, score=0.524, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=130, score=0.549, total=   0.3s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=130, score=0.567, total=   0.4s\n",
      "[CV] criterion=gini, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=gini, max_depth=3, max_features=log2, n_estimators=130, score=0.569, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=10, score=0.393, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=10, score=0.451, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=10, score=0.397, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=10, score=0.443, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=10, score=0.427, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=50, score=0.441, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=50, score=0.414, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=50, score=0.408, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=50, score=0.422, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=50, score=0.414, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=100, score=0.435, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=100, score=0.426, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=100, score=0.429, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=100, score=0.416, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=100, score=0.426, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=130, score=0.439, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=130, score=0.451, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=130, score=0.435, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=130, score=0.416, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=auto, n_estimators=130 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=2, max_features=auto, n_estimators=130, score=0.433, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=10, score=0.468, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=10, score=0.406, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=10, score=0.447, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=10, score=0.443, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=10, score=0.476, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=50, score=0.441, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=50, score=0.426, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=50, score=0.408, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=50, score=0.427, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=50, score=0.429, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=100, score=0.468, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=100, score=0.433, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=100, score=0.447, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=100, score=0.437, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=100, score=0.451, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=130, score=0.412, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=130, score=0.441, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=130, score=0.435, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=130, score=0.404, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=2, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=2, max_features=log2, n_estimators=130, score=0.431, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=10, score=0.549, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=10, score=0.493, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=10, score=0.516, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=10, score=0.547, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=10, score=0.540, total=   0.0s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=50, score=0.528, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=50, score=0.505, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=50, score=0.536, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=50, score=0.522, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=50, score=0.536, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=100, score=0.561, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=100, score=0.526, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=100, score=0.507, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=100, score=0.497, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=100, score=0.561, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=130, score=0.538, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=130, score=0.501, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=130, score=0.513, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=130, score=0.499, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=auto, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=auto, n_estimators=130, score=0.553, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=10, score=0.553, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=10, score=0.484, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=10, score=0.534, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=10, score=0.522, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=10, score=0.586, total=   0.1s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=50, score=0.567, total=   0.3s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=50, score=0.532, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=50, score=0.540, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=50, score=0.516, total=   0.4s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=50, score=0.576, total=   0.2s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=100, score=0.557, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=100, score=0.530, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=100, score=0.551, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=100, score=0.536, total=   0.5s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=100 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=100, score=0.580, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=130, score=0.567, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=130, score=0.532, total=   0.9s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=130, score=0.551, total=   0.6s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=130, score=0.524, total=   0.8s\n",
      "[CV] criterion=entropy, max_depth=3, max_features=log2, n_estimators=130 \n",
      "[CV]  criterion=entropy, max_depth=3, max_features=log2, n_estimators=130, score=0.561, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:   45.8s finished\n"
     ]
    }
   ],
   "source": [
    "random_forest=get_best_params_for_random_forest(x_train,y_train,rfr)\n",
    "prediction_random_forest=random_forest.predict(x_test)\n",
    "random_forest_score = accuracy_score(y_test,prediction_random_forest)\n",
    "#random_forest_score_1 = roc_auc_score(y_test, prediction_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stacking Object\n",
    "def stacking(x,y,meta_alg,algo_list=list):\n",
    "    \n",
    "    ''' x : Feature Columns\n",
    "        y : Target Column\n",
    "        meta_alg : Algorithm which will be used to blend rest of algorithm\n",
    "        algo_list: Base algorithms used in stacking '''\n",
    "    \n",
    "    #spliting data into training set and holding 50 % of data\n",
    "    train,val_train,test,val_test=train_test_split(x,y,test_size=0.5)\n",
    "    \n",
    "    # spliting training data into training and test data\n",
    "    x_train,x_test,y_train,y_test=train_test_split(train,test,test_size=0.2)\n",
    "    \n",
    "    # Here we are creating input data for Meta-Algo\n",
    "    predict=[]\n",
    "    # Fitting base models with train data\n",
    "    for i,algo in enumerate(algo_list):\n",
    "        z=algo.fit(x_train,y_train)\n",
    "        filename='base_model_'+str(i)+'.sav' # Saving Base models\n",
    "        with open(filename,'wb') as f:\n",
    "            pickle.dump(z,f)\n",
    "        # Here we are giving predictions on base models for validation data\n",
    "        i=z.predict(val_train)\n",
    "        predict.append(i)\n",
    "        predict_val=np.column_stack(predict) # Blending all predictions to feed meta-algo\n",
    "    \n",
    "    # Here we are creating input to check accuracy on Trained Meta-Algo\n",
    "    test=[]\n",
    "    for i,algo in enumerate(algo_list):\n",
    "        i=algo.predict(x_test)\n",
    "        test.append(i)\n",
    "        predict_test=np.column_stack(test)\n",
    "        \n",
    "    # Fitting meta algorithm with \n",
    "    model=meta_alg.fit(predict_val,val_test)\n",
    "    \n",
    "    # Uncheck below 3 lines to apply Cross-validation\n",
    "    #cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    #scores = cross_val_score(model, x, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    #print(score)\n",
    "    print('Test Score of meta algorithm is', meta_alg.score(predict_test,y_test))\n",
    "    print('Train Score of meta algorithm is', meta_alg.score(predict_val,val_test))\n",
    "    \n",
    "    #Saving Model for \n",
    "    filename='stacking_model.sav'\n",
    "    with open( filename, 'wb') as f:\n",
    "        pickle.dump(model,f)\n",
    "    print(model.accuracy())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score of meta algorithm is 0.7438271604938271\n",
      "Train Score of meta algorithm is 0.7654702970297029\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-32356952039e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstacking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlgbm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-1cf922acd8cb>\u001b[0m in \u001b[0;36mstacking\u001b[1;34m(x, y, meta_alg, algo_list)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'accuracy'"
     ]
    }
   ],
   "source": [
    "stacking(x,y,rfr,[rfr,svm,lgbm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(x):\n",
    "    with open('base_model_0.sav','rb') as f:\n",
    "        base_model_0=pickle.load(f)\n",
    "    with open('base_model_1.sav','rb') as f:\n",
    "        base_model_1=pickle.load(f)\n",
    "    with open('base_model_2.sav','rb') as f:\n",
    "        base_model_2=pickle.load(f)\n",
    "    with open('stacking_model.sav','rb') as f:\n",
    "        stacked_model=pickle.load(f)\n",
    "    \n",
    "    base_models=[base_model_0,base_model_1,base_model_2]\n",
    "    \n",
    "    x=np.array(x).reshape(1,-1)\n",
    "    \n",
    "    test=[]\n",
    "    for i,model in enumerate(base_models):\n",
    "        i=model.predict(x)\n",
    "        test.append(i)\n",
    "        prediction=np.column_stack(test)\n",
    "        print(prediction)\n",
    "        \n",
    "    prediction=stacked_model.predict(prediction)\n",
    "    result='Facies type is: {}'.format(prediction[0])\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[879,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.iloc[879,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]]\n",
      "[[6 2]]\n",
      "[[6 2 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Facies type is: 6'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_single(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_multiple(x):\n",
    "    with open('base_model_0.sav','rb') as f:\n",
    "        base_model_0=pickle.load(f)\n",
    "    with open('base_model_1.sav','rb') as f:\n",
    "        base_model_1=pickle.load(f)\n",
    "    with open('base_model_2.sav','rb') as f:\n",
    "        base_model_2=pickle.load(f)\n",
    "    with open('stacking_model.sav','rb') as f:\n",
    "        stacked_model=pickle.load(f)\n",
    "    \n",
    "    base_models=[base_model_0,base_model_1,base_model_2]\n",
    "    \n",
    "    #file=Path_of_file_folder+filename\n",
    "    #data=pd.read(file)\n",
    "    \n",
    "    test=[]\n",
    "    for i,model in enumerate(base_models):\n",
    "        i=model.predict(x)\n",
    "        test.append(i)\n",
    "        prediction=np.column_stack(test)\n",
    "        \n",
    "    prediction=stacked_model.predict(prediction)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2821.0</td>\n",
       "      <td>43.67</td>\n",
       "      <td>0.876</td>\n",
       "      <td>3.6</td>\n",
       "      <td>8.225</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2821.5</td>\n",
       "      <td>55.23</td>\n",
       "      <td>0.826</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7.875</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2822.0</td>\n",
       "      <td>61.24</td>\n",
       "      <td>0.777</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.575</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2822.5</td>\n",
       "      <td>54.46</td>\n",
       "      <td>0.728</td>\n",
       "      <td>12.8</td>\n",
       "      <td>10.660</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2823.0</td>\n",
       "      <td>43.23</td>\n",
       "      <td>0.699</td>\n",
       "      <td>14.9</td>\n",
       "      <td>12.375</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2823.5</td>\n",
       "      <td>44.59</td>\n",
       "      <td>0.682</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.540</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2824.0</td>\n",
       "      <td>47.48</td>\n",
       "      <td>0.676</td>\n",
       "      <td>16.5</td>\n",
       "      <td>12.890</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2824.5</td>\n",
       "      <td>61.10</td>\n",
       "      <td>0.671</td>\n",
       "      <td>15.2</td>\n",
       "      <td>11.785</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2825.0</td>\n",
       "      <td>64.82</td>\n",
       "      <td>0.680</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.970</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2825.5</td>\n",
       "      <td>55.77</td>\n",
       "      <td>0.710</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.930</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2826.0</td>\n",
       "      <td>62.22</td>\n",
       "      <td>0.744</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.215</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2826.5</td>\n",
       "      <td>55.06</td>\n",
       "      <td>0.786</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.500</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2827.0</td>\n",
       "      <td>71.02</td>\n",
       "      <td>0.839</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.890</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2827.5</td>\n",
       "      <td>91.37</td>\n",
       "      <td>0.881</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.060</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2828.0</td>\n",
       "      <td>115.42</td>\n",
       "      <td>0.911</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.875</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2828.5</td>\n",
       "      <td>115.70</td>\n",
       "      <td>0.940</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.085</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2829.0</td>\n",
       "      <td>107.11</td>\n",
       "      <td>0.972</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.135</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2829.5</td>\n",
       "      <td>93.82</td>\n",
       "      <td>1.008</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.640</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2830.0</td>\n",
       "      <td>61.63</td>\n",
       "      <td>1.061</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.865</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2830.5</td>\n",
       "      <td>45.98</td>\n",
       "      <td>1.076</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.250</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2831.0</td>\n",
       "      <td>32.76</td>\n",
       "      <td>1.071</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.225</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2831.5</td>\n",
       "      <td>37.82</td>\n",
       "      <td>1.058</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.190</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2832.0</td>\n",
       "      <td>40.73</td>\n",
       "      <td>1.038</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2832.5</td>\n",
       "      <td>33.42</td>\n",
       "      <td>1.005</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.610</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2833.0</td>\n",
       "      <td>32.08</td>\n",
       "      <td>0.968</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.355</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2833.5</td>\n",
       "      <td>33.82</td>\n",
       "      <td>0.943</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.330</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2834.0</td>\n",
       "      <td>45.57</td>\n",
       "      <td>0.924</td>\n",
       "      <td>1.1</td>\n",
       "      <td>8.840</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2834.5</td>\n",
       "      <td>53.95</td>\n",
       "      <td>0.900</td>\n",
       "      <td>1.9</td>\n",
       "      <td>8.125</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2835.0</td>\n",
       "      <td>59.42</td>\n",
       "      <td>0.875</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.845</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2835.5</td>\n",
       "      <td>68.43</td>\n",
       "      <td>0.854</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.665</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2836.0</td>\n",
       "      <td>75.88</td>\n",
       "      <td>0.849</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.040</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2836.5</td>\n",
       "      <td>77.75</td>\n",
       "      <td>0.864</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.850</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2837.0</td>\n",
       "      <td>80.93</td>\n",
       "      <td>0.907</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.815</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Depth      GR  ILD_log10  DeltaPHI   PHIND   PE  NM_M  RELPOS\n",
       "56  2821.0   43.67      0.876       3.6   8.225  4.1     2   0.741\n",
       "57  2821.5   55.23      0.826       5.1   7.875  4.3     2   0.722\n",
       "58  2822.0   61.24      0.777       9.7   8.575  4.3     2   0.704\n",
       "59  2822.5   54.46      0.728      12.8  10.660  4.4     2   0.685\n",
       "60  2823.0   43.23      0.699      14.9  12.375  4.0     2   0.667\n",
       "61  2823.5   44.59      0.682      16.0  13.540  3.9     2   0.648\n",
       "62  2824.0   47.48      0.676      16.5  12.890  3.7     2   0.630\n",
       "63  2824.5   61.10      0.671      15.2  11.785  3.7     2   0.611\n",
       "64  2825.0   64.82      0.680       9.1   8.970  4.5     2   0.574\n",
       "65  2825.5   55.77      0.710       6.1   8.930  5.1     2   0.556\n",
       "66  2826.0   62.22      0.744       4.3   9.215  5.5     2   0.537\n",
       "67  2826.5   55.06      0.786       2.9   9.500  5.6     2   0.519\n",
       "68  2827.0   71.02      0.839       3.1   8.890  5.4     2   0.500\n",
       "69  2827.5   91.37      0.881       3.9   8.060  5.3     2   0.481\n",
       "70  2828.0  115.42      0.911       5.2   6.875  5.3     2   0.463\n",
       "71  2828.5  115.70      0.940       5.9   6.085  5.2     2   0.444\n",
       "72  2829.0  107.11      0.972       6.0   6.135  5.6     2   0.426\n",
       "73  2829.5   93.82      1.008       5.8   6.640  5.6     2   0.407\n",
       "74  2830.0   61.63      1.061       3.6   6.865  6.1     2   0.370\n",
       "75  2830.5   45.98      1.076       3.6   6.250  6.2     2   0.352\n",
       "76  2831.0   32.76      1.071       3.0   6.225  5.8     2   0.333\n",
       "77  2831.5   37.82      1.058       3.6   6.190  5.7     2   0.315\n",
       "78  2832.0   40.73      1.038       2.3   6.375  5.5     2   0.296\n",
       "79  2832.5   33.42      1.005       2.2   6.610  5.4     2   0.278\n",
       "80  2833.0   32.08      0.968       2.2   7.355  5.3     2   0.259\n",
       "81  2833.5   33.82      0.943       2.1   8.330  4.9     2   0.241\n",
       "82  2834.0   45.57      0.924       1.1   8.840  4.7     2   0.222\n",
       "83  2834.5   53.95      0.900       1.9   8.125  4.6     2   0.204\n",
       "84  2835.0   59.42      0.875       4.3   7.845  4.6     2   0.185\n",
       "85  2835.5   68.43      0.854       8.3   8.665  4.8     2   0.167\n",
       "86  2836.0   75.88      0.849      11.0  10.040  4.6     2   0.148\n",
       "87  2836.5   77.75      0.864      11.3  10.850  4.7     2   0.130\n",
       "88  2837.0   80.93      0.907       9.6   9.815  4.6     2   0.111"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data.iloc[56:89,1:]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 7, 7, 4, 4, 8, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_multiple(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56    6\n",
       "57    6\n",
       "58    6\n",
       "59    6\n",
       "60    7\n",
       "61    7\n",
       "62    4\n",
       "63    4\n",
       "64    4\n",
       "65    4\n",
       "66    4\n",
       "67    6\n",
       "68    6\n",
       "69    6\n",
       "70    6\n",
       "71    6\n",
       "72    6\n",
       "73    6\n",
       "74    6\n",
       "75    6\n",
       "76    6\n",
       "77    6\n",
       "78    6\n",
       "79    6\n",
       "80    6\n",
       "81    6\n",
       "82    6\n",
       "83    6\n",
       "84    6\n",
       "85    6\n",
       "86    6\n",
       "87    6\n",
       "88    6\n",
       "Name: Facies, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[56:89,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantity=np.array([2,3,4,5,6,7,2,5])\n",
    "price=np.array([9,18,22,34,48,52,8,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.25, 24.75)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity.mean(),price.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.82995169],\n",
       "       [0.82995169, 1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(quantity, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'Quantity': quantity, 'Price': price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Quantity  Price\n",
       "0         2      9\n",
       "1         3     18\n",
       "2         4     22\n",
       "3         5     34\n",
       "4         6     48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8299516905782974"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Quantity'].corr(dataset['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
